{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZJ7UJlKnwJk3",
        "StemrBe2wkMj",
        "DMJVaj_kxj42"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lilwm/Optimizing-DataFrames-and-Processing-in-Chunks/blob/main/Optimizing_DataFrames_and_Processing_in_Chunks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7eHGTSKv8TW"
      },
      "source": [
        "# Project Notebook: Optimizing DataFrames and Processing in Chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ7UJlKnwJk3"
      },
      "source": [
        "## 1. Introduction "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUyK3GcBv9mC"
      },
      "source": [
        "In this project, we'll practice working with chunked dataframes and optimizing a dataframe's memory usage. We'll be working with financial lending data from Lending Club, a marketplace for personal loans that matches borrowers with investors. You can read more about the marketplace on its website.\n",
        "\n",
        "The Lending Club's website lists approved loans. Qualified investors can view the borrower's credit score, the purpose of the loan, and other details in the loan applications. Once a lender is ready to back a loan, it selects the amount of money it wants to fund. When the loan amount the borrower requested is fully funded, the borrower receives the money, minus the origination fee that Lending Club charges.\n",
        "\n",
        "We'll be working with a dataset of loans approved from 2007-2011 (https://bit.ly/3H2XVgC). We've already removed the desc column for you to make our system run more quickly.\n",
        "\n",
        "If we read in the entire data set, it will consume about 67 megabytes of memory. Let's imagine that we only have 10 megabytes of memory available throughout this project, so you can practice the concepts you learned in the last two lessons.\n",
        "\n",
        "**Tasks**\n",
        "\n",
        "1. Read in the first five lines from `loans_2007.csv` (https://bit.ly/3H2XVgC) and look for any data quality issues.\n",
        "\n",
        "2. Read in the first 1000 rows from the data set, and calculate the total memory usage for these rows. Increase or decrease the number of rows to converge on a memory usage under five megabytes (to stay on the conservative side)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc9NLSZ5vXPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd701b59-7685-448f-bc5b-6b57568a025d"
      },
      "source": [
        "\n",
        "# Importing pandas\n",
        "import pandas as pd\n",
        "pd.options.display.max_columns = 99\n",
        "\n",
        "# Your code goes here\n",
        "loans_df = pd.read_csv('https://bit.ly/3H2XVgC')\n",
        "loans_df.head()\n",
        "\n",
        "#Read in the first 1000 rows from the data set, and calculate the total memory usage for these rows \n",
        "loans_df2 = pd.read_csv('https://bit.ly/3H2XVgC', nrows=1000)\n",
        "print(\"usage(MB) for 1000 rows: \",loans_df2.memory_usage(deep=True).sum()/(1024**2))"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage(MB) for 1000 rows:  1.5273666381835938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Increase the number of rows 3 times\n",
        "loans_df = pd.read_csv('https://bit.ly/3H2XVgC', nrows=3000)\n",
        "print(loans_df.memory_usage(deep=True).sum() / (1024**2), 'MB')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7YI3WhEHyPS",
        "outputId": "902379cd-eac0-40cb-df3b-c939f7c39fb9"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.580394744873047 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*loading the first 3000 rows seems to keep the memory usage under 5 MB*"
      ],
      "metadata": {
        "id": "gIvFEeC6Xdq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loan_iter = pd.read_csv('https://bit.ly/3H2XVgC', chunksize=3000)\n",
        "\n",
        "for chunk in loan_iter:\n",
        "  print(chunk.memory_usage(deep=True).sum() / (1024**2), 'MB')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRdFh7qxQLlW",
        "outputId": "95d090d9-7df7-45ca-c5c1-fc6ebe8a4386"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.580394744873047 MB\n",
            "4.576141357421875 MB\n",
            "4.577898979187012 MB\n",
            "4.579251289367676 MB\n",
            "4.575444221496582 MB\n",
            "4.577326774597168 MB\n",
            "4.575918197631836 MB\n",
            "4.578287124633789 MB\n",
            "4.576413154602051 MB\n",
            "4.57646369934082 MB\n",
            "4.589176177978516 MB\n",
            "4.588043212890625 MB\n",
            "4.594850540161133 MB\n",
            "4.828314781188965 MB\n",
            "0.868586540222168 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*All the chunks of our dataset consume less than 5 MB as required*"
      ],
      "metadata": {
        "id": "PEEl1DsmX6QZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StemrBe2wkMj"
      },
      "source": [
        "## 2. Exploring the Data in Chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm4p982Dwor5"
      },
      "source": [
        "Let's familiarize ourselves with the columns to see which ones we can optimize. In the first lesson, we explored column types by reading in the full dataframe. In this project, let's try to understand the column types better while using dataframe chunks.\n",
        "\n",
        "**Tasks**\n",
        "\n",
        "For each chunk:\n",
        "* How many columns have a numeric type? \n",
        "* How many have a string type?\n",
        "* How many unique values are there in each string column? How many of the string columns contain values that are less than 50% unique?\n",
        "* Which float columns have no missing values and could be candidates for conversion to the integer type?\n",
        "* Calculate the total memory usage across all of the chunks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loan_iter = pd.read_csv('https://bit.ly/3H2XVgC', chunksize=3000)\n",
        "\n",
        "numeric = []\n",
        "string = []\n",
        "for chunk in loan_iter:\n",
        "    # Calculate amount of columns for each type per chunk\n",
        "    numeric.append(chunk.select_dtypes(include='number').shape[1])\n",
        "    string.append(chunk.select_dtypes(include='object').shape[1])\n",
        "    \n",
        "print(f'Numeric columns per chunk: \\n{numeric}')\n",
        "\n",
        "print('\\nString columns per chunk:\\n', string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Cmy3Qh6YUTF",
        "outputId": "6c2c1304-886b-4e77-82c0-f7725e955d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric columns per chunk: \n",
            "[31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 30, 30]\n",
            "\n",
            "String columns per chunk:\n",
            " [21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obj_cols = []\n",
        "loan_iter = pd.read_csv('https://bit.ly/3H2XVgC', chunksize=3000)\n",
        "\n",
        "for chunk in loan_iter:\n",
        "    chunk_obj_cols = chunk.select_dtypes(include=['object']).columns.tolist()\n",
        "    if len(obj_cols) > 0:\n",
        "        similar = obj_cols == chunk_obj_cols\n",
        "        if not similar:\n",
        "            print(\"overall string cols:\\n\", obj_cols, \"\\n\")\n",
        "            print(\"chunk string cols:\\n\", chunk_obj_cols, \"\\n\")    \n",
        "    else:\n",
        "        obj_cols = chunk_obj_cols"
      ],
      "metadata": {
        "id": "wUbtMqtvZI78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d555429-4635-4fb9-89bd-007f8c71dcfc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "overall string cols:\n",
            " ['term', 'int_rate', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'purpose', 'title', 'zip_code', 'addr_state', 'earliest_cr_line', 'revol_util', 'initial_list_status', 'last_pymnt_d', 'last_credit_pull_d', 'application_type'] \n",
            "\n",
            "chunk string cols:\n",
            " ['id', 'term', 'int_rate', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'purpose', 'title', 'zip_code', 'addr_state', 'earliest_cr_line', 'revol_util', 'initial_list_status', 'last_pymnt_d', 'last_credit_pull_d', 'application_type'] \n",
            "\n",
            "overall string cols:\n",
            " ['term', 'int_rate', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'purpose', 'title', 'zip_code', 'addr_state', 'earliest_cr_line', 'revol_util', 'initial_list_status', 'last_pymnt_d', 'last_credit_pull_d', 'application_type'] \n",
            "\n",
            "chunk string cols:\n",
            " ['id', 'term', 'int_rate', 'grade', 'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'purpose', 'title', 'zip_code', 'addr_state', 'earliest_cr_line', 'revol_util', 'initial_list_status', 'last_pymnt_d', 'last_credit_pull_d', 'application_type'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations \n",
        "*   There are 31 numeric columns and 21 string columns in most chunks except the last 2\n",
        "*  It seems like the *id column* is being cast to int64 in the last 2 chunks but not in the earlier chunks. Since the id column won't be useful for analysis we can ignore this column.\n",
        "\n"
      ],
      "metadata": {
        "id": "R5wQS2phZmcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check for string values less than 50%\n",
        "loan_iter = pd.read_csv('https://bit.ly/3H2XVgC', chunksize=3000)\n",
        "\n",
        "unique_percent =[]\n",
        "for chunk in loan_iter:\n",
        "  chunk['id'] = pd.to_numeric(chunk['id'], errors='coerce') #non-numeric string converted to null values\n",
        "  chunk = chunk.dropna(axis=0, subset=['id']) #drop row where id is missing\n",
        "  string_cols_unique = chunk.select_dtypes(include=['object']).nunique() #check unique values per col\n",
        "  string_cols_count = chunk.select_dtypes(include=['object']).count() # get total no of items in col\n",
        "  unique_percent.append((100*string_cols_unique/string_cols_count))  # get unique%\n",
        "  total_unique = pd.concat(unique_percent)\n",
        "  total_unique = total_unique.groupby(total_unique.index).mean()\n",
        "  string_cols_categorical = list((total_unique[total_unique <50]).index)\n",
        "\n",
        "print(print(f'\\npercent of unique values:  \\n{total_unique}'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "922i_ouhaqyc",
        "outputId": "fc1739d7-42c6-4424-ca75-09ef830596a2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "percent of unique values:  \n",
            "addr_state              1.880203\n",
            "application_type        0.043550\n",
            "earliest_cr_line       14.686817\n",
            "emp_length              0.488414\n",
            "emp_title              92.775698\n",
            "grade                   0.304848\n",
            "home_ownership          0.156422\n",
            "initial_list_status     0.043550\n",
            "int_rate                3.376513\n",
            "issue_d                 0.343083\n",
            "last_credit_pull_d      3.309096\n",
            "last_pymnt_d            2.488140\n",
            "loan_status             0.149323\n",
            "purpose                 0.579480\n",
            "pymnt_plan              0.045772\n",
            "revol_util             34.412441\n",
            "sub_grade               1.517572\n",
            "term                    0.070217\n",
            "title                  64.571386\n",
            "verification_status     0.105773\n",
            "zip_code               20.765791\n",
            "dtype: float64\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Float columns with no missing values\n",
        "loan_iter = pd.read_csv('https://bit.ly/3H2XVgC', chunksize=3000)\n",
        "\n",
        "float_null_count =[]\n",
        "for chunk in loan_iter:\n",
        "  chunk['id'] = pd.to_numeric(chunk['id'], errors='coerce') #non-numeric string converted to null values\n",
        "  chunk = chunk.dropna(axis=0, subset=['id']) #drop row where id is missing\n",
        "  float_cols_null = chunk.select_dtypes(exclude=['object']).isnull().sum()\n",
        "  float_null_count.append(float_cols_null)\n",
        "  #combine all numeric columns missing values\n",
        "  total_float_null = pd.concat(float_null_count)\n",
        "  total_float_null = total_float_null.groupby(total_float_null.index).sum()\n",
        "  no_missing = set((total_float_null[total_float_null == 0 ]).index)\n",
        "  missing = set((total_float_null[total_float_null > 0 ]).index)\n",
        "\n",
        "print(f'float columns with missing values:  \\n{missing}')\n",
        "print(f'\\nfloat columns with no missing values:  \\n{no_missing}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgRcNEoWcW8M",
        "outputId": "10e0b533-ade2-4850-ae9f-01b41c734c51"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float columns with missing values:  \n",
            "{'tax_liens', 'chargeoff_within_12_mths', 'annual_inc', 'collections_12_mths_ex_med', 'delinq_amnt', 'total_acc', 'open_acc', 'delinq_2yrs', 'pub_rec_bankruptcies', 'inq_last_6mths', 'acc_now_delinq', 'pub_rec'}\n",
            "\n",
            "float columns with no missing values:  \n",
            "{'out_prncp', 'funded_amnt_inv', 'total_rec_prncp', 'loan_amnt', 'total_rec_late_fee', 'last_pymnt_amnt', 'total_pymnt', 'installment', 'out_prncp_inv', 'collection_recovery_fee', 'revol_bal', 'funded_amnt', 'member_id', 'total_pymnt_inv', 'total_rec_int', 'recoveries', 'id', 'policy_code', 'dti'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# total memory usage \n",
        "loans_iter = pd.read_csv('https://bit.ly/3H2XVgC', chunksize=3000)\n",
        "\n",
        "initial_memory = []\n",
        "for chunk in loans_iter:\n",
        "    initial_memory.append(chunk.memory_usage(deep=True).sum() / (1024 ** 2))\n",
        "    \n",
        "print('Total memory usage: {:.4f} MB'.format(sum(initial_memory)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_trQD2uvbz5M",
        "outputId": "f34a9b25-10f7-4841-e960-a260c916177f"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total memory usage: 65.2425 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Initial memory usage is 65.24MB. This will be our reference when lowering the amount of total memory usage.*"
      ],
      "metadata": {
        "id": "Sz_kVlTQf6dz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BtAVP8fw3OH"
      },
      "source": [
        "## 3. Optimizing String Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkWArHAhw_bw"
      },
      "source": [
        "We can achieve the greatest memory improvements by converting the string columns to a numeric type. Let's convert all of the columns where the values are less than 50% unique to the category type, and the columns that contain numeric values to the `float` type.\n",
        "\n",
        "While working with dataframe chunks:\n",
        "* Determine which string columns you can convert to a numeric type if you clean them. For example, the `int_rate` column is only a string because of the % sign at the end.\n",
        "* Determine which columns have a few unique values and convert them to the category type. For example, you may want to convert the grade and `sub_grade` columns.\n",
        "Based on your conclusions, perform the necessary type changes across all chunks. * Calculate the total memory footprint, and compare it with the previous one."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can convert the above  object columns into the following dtypes\n",
        "       # To Category: [sub_grade, 'home_ownership', 'verification_status','purpose']\n",
        "        # To numerical: ['term', 'revol_util', 'int_rate']\n",
        "        # To datetime:['issue_d', 'earliest_cr_line','last_pymnt_d','last_credit_pull_d']\n",
        "convert_col_dtypes = {\n",
        "    \"sub_grade\": \"category\", \"home_ownership\": \"category\", \n",
        "    \"verification_status\": \"category\", \"purpose\": \"category\"\n",
        "}\n",
        "#pass the dtypes when reading the df\n",
        "loan_iter = pd.read_csv('https://bit.ly/3H2XVgC', chunksize=3000, dtype=convert_col_dtypes, \n",
        "                         parse_dates=[\"issue_d\", \"earliest_cr_line\", \"last_pymnt_d\", \"last_credit_pull_d\"])\n",
        "total_memory = []\n",
        "for chunk in loan_iter:\n",
        "    term_cleaned = chunk['term'].str.lstrip(\" \").str.rstrip(\" months\")  #remove months to convert to int\n",
        "    int_rate_cleaned = chunk['int_rate'].str.rstrip(\"%\")\n",
        "    revol_cleaned = chunk['revol_util'].str.rstrip(\"%\") #remove % \n",
        "    chunk['term'] = pd.to_numeric(term_cleaned)\n",
        "    chunk['revol_util'] = pd.to_numeric(revol_cleaned)\n",
        "    chunk['int_rate'] = pd.to_numeric(int_rate_cleaned)\n",
        "    total_memory.append(chunk.memory_usage(deep=True).sum() / (1024 ** 2))\n",
        "    \n",
        "# print(chunk.dtypes)\n",
        "print('\\nTotal memory usage with string optimization: {:.2f} MB'.format(sum(total_memory)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYpDZcpXk5V7",
        "outputId": "2aa002bb-1eed-4020-c748-83d292a26f48"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total memory usage with string optimization: 38.81 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observation\n",
        "*Memory usage improved from **65.25MB to 38.8MB** after changing data to categorical*"
      ],
      "metadata": {
        "id": "uKPUyve_LZm4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22oYzgXnxIcV"
      },
      "source": [
        "## 4. Optimizing Numeric Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv5C20YrxPID"
      },
      "source": [
        "It looks like we were able to realize some powerful memory savings by converting to the category type and converting string columns to numeric ones.\n",
        "\n",
        "Now let's optimize the numeric columns using the `pandas.to_numeric()` function.\n",
        "\n",
        "**Tasks**\n",
        "\n",
        "While working with dataframe chunks:\n",
        "* Identify float columns that contain missing values, and that we can convert to a more space efficient subtype.\n",
        "* Identify float columns that don't contain any missing values, and that we can convert to the integer type because they represent whole numbers.\n",
        "* Based on your conclusions, perform the necessary type changes across all chunks.\n",
        "* Calculate the total memory footprint and compare it with the previous one.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**float to more efficient subtype conversion**\n",
        "\n",
        "in this step, we deal with the columns that have missing values"
      ],
      "metadata": {
        "id": "6JuVeEmbSYMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check for NaN values\n",
        "loans_df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-Mn6Gq6fO4X",
        "outputId": "3042bdf6-c682-4e51-8bd6-1aeadfcabff4"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                            0\n",
              "member_id                     0\n",
              "loan_amnt                     0\n",
              "funded_amnt                   0\n",
              "funded_amnt_inv               0\n",
              "term                          0\n",
              "int_rate                      0\n",
              "installment                   0\n",
              "grade                         0\n",
              "sub_grade                     0\n",
              "emp_title                     0\n",
              "emp_length                    0\n",
              "home_ownership                0\n",
              "annual_inc                    0\n",
              "verification_status           0\n",
              "issue_d                       0\n",
              "loan_status                   0\n",
              "pymnt_plan                    0\n",
              "purpose                       0\n",
              "title                         0\n",
              "zip_code                      0\n",
              "addr_state                    0\n",
              "dti                           0\n",
              "delinq_2yrs                   0\n",
              "earliest_cr_line              0\n",
              "inq_last_6mths                0\n",
              "open_acc                      0\n",
              "pub_rec                       0\n",
              "revol_bal                     0\n",
              "revol_util                    0\n",
              "total_acc                     0\n",
              "initial_list_status           0\n",
              "out_prncp                     0\n",
              "out_prncp_inv                 0\n",
              "total_pymnt                   0\n",
              "total_pymnt_inv               0\n",
              "total_rec_prncp               0\n",
              "total_rec_int                 0\n",
              "total_rec_late_fee            0\n",
              "recoveries                    0\n",
              "collection_recovery_fee       0\n",
              "last_pymnt_d                  0\n",
              "last_pymnt_amnt               0\n",
              "last_credit_pull_d            0\n",
              "collections_12_mths_ex_med    0\n",
              "policy_code                   0\n",
              "application_type              0\n",
              "acc_now_delinq                0\n",
              "chargeoff_within_12_mths      0\n",
              "delinq_amnt                   0\n",
              "pub_rec_bankruptcies          0\n",
              "tax_liens                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here\n",
        "\n",
        "loan_iter = pd.read_csv('https://bit.ly/3H2XVgC', chunksize=3000, dtype=convert_col_dtypes, \n",
        "                         parse_dates=[\"issue_d\", \"earliest_cr_line\", \"last_pymnt_d\", \"last_credit_pull_d\"], )\n",
        "import numpy as np\n",
        "#function to convert to int for cols with no missing values\n",
        "def change_to_int(df, col_name):\n",
        "    # Get the min and max values\n",
        "    max_col = df[col_name].max()\n",
        "    min_col = df[col_name].min()\n",
        "    # Find the datatype\n",
        "    for dtype_name in ['int8', 'int16', 'int32', 'int64']:\n",
        "        # Check if this datatype can hold all values\n",
        "        if max_col <  np.iinfo(dtype_name).max and min_col > np.iinfo(dtype_name).min:\n",
        "            df[col_name] = df[col_name].astype(dtype_name)\n",
        "            break\n",
        "\n",
        "total_memory = []\n",
        "for chunk in loan_iter:\n",
        "  #convert the id column object to float and remove null value\n",
        "  chunk['id'] = pd.to_numeric(chunk['id'], errors='coerce') #non-numeric string converted to null values\n",
        "  chunk = chunk.dropna(axis=0, subset=['id']) #drop row where id is missing\n",
        "  term_cleaned = chunk['term'].str.lstrip(\" \").str.rstrip(\" months\")  #remove months to convert to int\n",
        "  int_rate_cleaned = chunk['int_rate'].str.rstrip(\"%\")\n",
        "  revol_cleaned = chunk['revol_util'].str.rstrip(\"%\") #remove % \n",
        "  chunk['term'] = pd.to_numeric(term_cleaned)\n",
        "  chunk['revol_util'] = pd.to_numeric(revol_cleaned)\n",
        "  chunk['int_rate'] = pd.to_numeric(int_rate_cleaned)\n",
        "\n",
        "  float_cols = chunk.select_dtypes(include=['float'])\n",
        "  float_cols = float_cols.dropna()\n",
        "  for col in float_cols.columns:\n",
        "    if col in missing:\n",
        "      chunk[col] = pd.to_numeric(chunk[col], downcast='float')\n",
        "    elif col in no_missing:\n",
        "      change_to_int(chunk, col)\n",
        "  #calculate memory usage\n",
        "  total_memory.append(chunk.memory_usage(deep=True).sum() / (1024 ** 2))\n",
        "\n",
        "print('\\nTotal memory usage: {:.2f} MB'.format(sum(total_memory)))\n",
        "print('\\nPercentage memory savings: {:.2f} %'.format(100*(sum(initial_memory) - sum(total_memory))/sum(initial_memory)))\n",
        "print(f'\\n {chunk.dtypes}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQsjZbSLSOMG",
        "outputId": "2bf02d4a-f3e6-46b5-db12-0fdbed1c497a"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total memory usage: 32.99 MB\n",
            "\n",
            "Percentage memory savings: 49.44 %\n",
            "\n",
            " id                                     int32\n",
            "member_id                              int32\n",
            "loan_amnt                              int16\n",
            "funded_amnt                            int16\n",
            "funded_amnt_inv                        int16\n",
            "term                                   int64\n",
            "int_rate                             float64\n",
            "installment                            int16\n",
            "grade                                 object\n",
            "sub_grade                           category\n",
            "emp_title                             object\n",
            "emp_length                            object\n",
            "home_ownership                      category\n",
            "annual_inc                           float32\n",
            "verification_status                 category\n",
            "issue_d                       datetime64[ns]\n",
            "loan_status                           object\n",
            "pymnt_plan                            object\n",
            "purpose                             category\n",
            "title                                 object\n",
            "zip_code                              object\n",
            "addr_state                            object\n",
            "dti                                     int8\n",
            "delinq_2yrs                          float32\n",
            "earliest_cr_line              datetime64[ns]\n",
            "inq_last_6mths                       float32\n",
            "open_acc                             float32\n",
            "pub_rec                              float32\n",
            "revol_bal                              int32\n",
            "revol_util                           float64\n",
            "total_acc                            float32\n",
            "initial_list_status                   object\n",
            "out_prncp                               int8\n",
            "out_prncp_inv                           int8\n",
            "total_pymnt                            int32\n",
            "total_pymnt_inv                        int16\n",
            "total_rec_prncp                        int16\n",
            "total_rec_int                          int16\n",
            "total_rec_late_fee                      int8\n",
            "recoveries                             int16\n",
            "collection_recovery_fee                int16\n",
            "last_pymnt_d                  datetime64[ns]\n",
            "last_pymnt_amnt                        int16\n",
            "last_credit_pull_d            datetime64[ns]\n",
            "collections_12_mths_ex_med           float32\n",
            "policy_code                             int8\n",
            "application_type                      object\n",
            "acc_now_delinq                       float32\n",
            "chargeoff_within_12_mths             float32\n",
            "delinq_amnt                          float32\n",
            "pub_rec_bankruptcies                 float32\n",
            "tax_liens                            float32\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*we managed to achieve 49.44% savings on memory. By further optimizing the integer data types, memory usage dropped to ~33MB from 65MB*"
      ],
      "metadata": {
        "id": "dHdARlvhlJhA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMJVaj_kxj42"
      },
      "source": [
        "## Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0RL3BzexlkW"
      },
      "source": [
        "We've practiced optimizing a dataframe's memory footprint and working with dataframe chunks. Here's an idea for some next steps:\n",
        "\n",
        "Create a function that automates as much of the work you just did as possible, so that you could use it on other Lending Club data sets. This function should:\n",
        "\n",
        "* Determine the optimal chunk size based on the memory constraints you provide.\n",
        "\n",
        "* Determine which string columns can be converted to numeric ones by removing the `%` character.\n",
        "\n",
        "* Determine which numeric columns can be converted to more space efficient representations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hvuUNzPx1zy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d160726f-25aa-4fea-d154-051f6dc07e04"
      },
      "source": [
        "# Your code goes here\n",
        "# Determine the optimal chunk size based on the memory constraints you provide.\n",
        "\n",
        "def optimal_chunk_size(csv_file, desired_mem, row_steps, start_chunk_size):\n",
        "  no_rows = start_chunk_size\n",
        "  chunk_memory =0\n",
        "  while(chunk_memory < desired_mem):\n",
        "    no_rows += row_steps\n",
        "    chunk = pd.read_csv(csv_file, nrows=no_rows)\n",
        "    chunk_memory = chunk.memory_usage(deep=True).sum()/(1024**2)\n",
        "  return(no_rows - row_steps) # reduce by 1\n",
        "\n",
        "optimal_chunk_size('https://bit.ly/3H2XVgC', 5, 50, 2500)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3250"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine which string columns can be converted to numeric ones by removing the % character\n",
        "def string_to_numeric(df, character):\n",
        "  columns_with_char = []\n",
        "  for key, value in df.iteritems():\n",
        "    if  value.str.contains(character).any(): #check if column has % character\n",
        "      try:\n",
        "        value = value.str.replace('%', '')  #remove it and try to convert to numeric\n",
        "        value = pd.to_numeric(value, errors='raise') \n",
        "        columns_with_char.append(key)\n",
        "      except(ValueError):\n",
        "        #dont add columns to the list\n",
        "        continue\n",
        "  print(columns_with_char)\n",
        "\n",
        "loans = pd.read_csv('https://bit.ly/3H2XVgC')\n",
        "string_cols = loans.select_dtypes(include='object')\n",
        "string_to_numeric(string_cols, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk4vwSoKzk25",
        "outputId": "149cd6cf-f493-46de-abc2-4505691f83b2"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['int_rate', 'revol_util']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Determine which numeric columns can be converted to more space efficient representations\n",
        "\n",
        "# int64(no missing value) or float64(allow missing value)\n",
        "def numeric_mem_optimise(df): \n",
        "  #select float type columns and check the number of missing value per columns\n",
        "  numeric_cols = df.select_dtypes(exclude=['object'])\n",
        "  cols_missing_value = numeric_cols.isnull().sum()\n",
        "  #float columns with no null values can be converted to int type\n",
        "  int_cols = list(cols_missing_value[cols_missing_value == 0].index)\n",
        "  float_cols = list(cols_missing_value[cols_missing_value >0].index)\n",
        "\n",
        "  return int_cols, float_cols\n",
        "\n",
        "#\n",
        "loans = pd.read_csv('https://bit.ly/3H2XVgC')\n",
        "loans['id']=pd.to_numeric(loans['id'], errors='coerce')\n",
        "loans.dropna(axis=0, subset=['id'], inplace=True)\n",
        "\n",
        "x,y = numeric_mem_optimise(loans)\n",
        "print(f'int columns: {x}')\n",
        "print(f'float columns: {y}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVJQymy81fJJ",
        "outputId": "37d18a40-8324-4028-ab30-109e3e158e46"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "int columns: ['id', 'member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'installment', 'dti', 'revol_bal', 'out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_pymnt_amnt', 'policy_code']\n",
            "float columns: ['annual_inc', 'delinq_2yrs', 'inq_last_6mths', 'open_acc', 'pub_rec', 'total_acc', 'collections_12_mths_ex_med', 'acc_now_delinq', 'chargeoff_within_12_mths', 'delinq_amnt', 'pub_rec_bankruptcies', 'tax_liens']\n"
          ]
        }
      ]
    }
  ]
}